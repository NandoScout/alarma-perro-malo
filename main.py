#!/usr/bin/env python
# -*- coding: UTF-8 -*-
#
# generated by wxGlade 0.9.3 on Thu Jun  6 17:54:54 2019
#

import wx
import cv2
import numpy as np
import os
from os import listdir
from os.path import isfile, join
from itertools import cycle
import sys
import tarfile
import tensorflow as tf
import zipfile
import collections
from collections import defaultdict
from io import StringIO
from matplotlib import pyplot as plt
from PIL import Image

from datetime import datetime as time
from time import sleep
from urllib.parse import urlparse
import glob
import xml.etree.ElementTree as ET
from collections import namedtuple
import socket
import win32gui
import win32con
from win32api import GetSystemMetrics
import vlc
import winsound

drawing = False
x1 = 0
y1 = 0
x2 = 0
y2 = 0
image_np=0

def on_mouse(event, x, y, flags, params):
    # global img
    t = time  
    frequency = 1000  # Set Frequency
    duration = 200  # Set Duration To 1000 ms == 1 second
    global x1,y1,x2,y2,drawing,image_np

    if(event==1):
          drawing = True
          x1 = x
          y1 = y
          winsound.Beep(frequency, duration)
    if(event==0):
          if(drawing==True):
              #For Drawing Line
              #cv2.line(image_np,pt1=(ix,iy),pt2=(x,y),color=(255,255,255),thickness=3)
              # For Drawing Rectangle
              #recuadro de la toma de video
              x2 = x
              y2 = y

              #ix = x
              #iy = y

    if(event==4):
          drawing = False
          winsound.Beep(frequency, duration)

def windowEnumerationHandler(hwnd, top_windows):
    top_windows.append((hwnd, win32gui.GetWindowText(hwnd)))

# Importación del módulo de detección de objetos.
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_util


# begin wxGlade: dependencies
# end wxGlade

# begin wxGlade: extracode
# end wxGlade


class MyFrame(wx.Frame):
    def __init__(self, *args, **kwds):
          
        
        # begin wxGlade: MyFrame.__init__
        kwds["style"] = kwds.get("style", 0) | wx.DEFAULT_FRAME_STYLE
        wx.Frame.__init__(self, *args, **kwds)
        self.SetSize((812, 522))
        
        self.Bind(wx.EVT_KEY_DOWN, self.KeyDown)

        # Menu Bar
        self.frame_menubar = wx.MenuBar()
        wxglade_tmp_menu = wx.Menu()
        item = wxglade_tmp_menu.Append(wx.ID_ANY, u"Configuración", "")
        self.Bind(wx.EVT_MENU, self.configuraciónClick, id=item.GetId())
        item = wxglade_tmp_menu.Append(wx.ID_ANY, "Acerca de...", "")
        self.Bind(wx.EVT_MENU, self.acercaDeClick, id=item.GetId())
        item = wxglade_tmp_menu.Append(wx.ID_ANY, "Salir", "")
        self.Bind(wx.EVT_MENU, self.salirClick, id=item.GetId())
        self.frame_menubar.Append(wxglade_tmp_menu, "Menu")
        wxglade_tmp_menu = wx.Menu()
        item = wxglade_tmp_menu.Append(wx.ID_ANY, "Start/Stop", "")
        self.Bind(wx.EVT_MENU, self.cambiarEstadoCNN, id=item.GetId())
        self.frame_menubar.Append(wxglade_tmp_menu, "CNN")
        self.SetMenuBar(self.frame_menubar)
        # Menu Bar end
        self.label_1 = wx.StaticText(self, wx.ID_ANY, "Ubicaciones:")
        self.cantUbicaciones = wx.StaticText(self, wx.ID_ANY, "0")
        self.label_2 = wx.StaticText(self, wx.ID_ANY, "Ocupadas: ")
        self.cantOcupadas = wx.StaticText(self, wx.ID_ANY, "0")
        self.label_3 = wx.StaticText(self, wx.ID_ANY, "Libres:")
        self.cantLibres = wx.StaticText(self, wx.ID_ANY, "0")

        self.__set_properties()
        self.__do_layout()

        # end wxGlade
             
        self.PATH_VIDEOS='videos'
        lista = [f for f in listdir(self.PATH_VIDEOS) if isfile(join(self.PATH_VIDEOS, f)) and os.path.splitext(join(self.PATH_VIDEOS, f))[1]==".mp4"]
        self.listaVideos = cycle(lista)
        self.personas=0
        self.pause=False
        self.forzarPausa=False
        self.personasTotales=0

        #Create objects
        self.CaptureWidth = 640
        self.CaptureHeight = 480

        #Para Camara en vivo
        self.Screen1Width = 550
        self.Screen1Height = 300
        self.Screen1 = wx.StaticBitmap(self, size = (self.Screen1Width, self.Screen1Height)) # Static bitmaps for OpenCV images

        img = wx.Image('imagenes/negro.png').Scale(self.Screen1Width, self.Screen1Height, wx.IMAGE_QUALITY_HIGH)
        self.wxbmp = img.ConvertToBitmap()
        self.num=-1
        self.boxes=0
        self.scores=0
        self.classes=0
		
        self.sizer_2.Add( self.Screen1, 1, wx.FIXED_MINSIZE |wx.ALL, 5 )
                     
        self.Screen1.Bind(wx.EVT_ERASE_BACKGROUND, self.onEraseBackground)              
        self.Screen1.Bind(wx.EVT_PAINT, self.onPaint)

        # Add objects to sizer
        #self.sizer_2.Add(self.Screen1, 0, wx.EXPAND | wx.ALL, 10)

        #Para resultado del analisis
        self.Screen2Width = 550
        self.Screen2Height = 270
        
        #Maximizo ventana para que ocupe todo el escritorio menos la barra de tareas
        c_x, c_y, c_w, c_h = wx.ClientDisplayRect()
        self.SetSize((c_w, c_h))
        self.SetPosition((c_x, c_y))
        
        #Ventana mitad de escritorio
        self.SetSize((c_w/2, c_h))
        self.SetPosition((c_w/2, c_y))

  
        #Obtengo la posicion, dentro de la toma completa, de cada ubicacion 
        path_locations='configuracion'
        self.images_location=self.xml_to_locations(path_locations)
        self.cantUbicaciones.Label=str(len(self.images_location))
        self.cantLibres.Label=str(len(self.images_location))
        #Lista para guardar el estado de cada banca:
        # [OK] = ocupada
        # [ ] = libre
        # [?] = indeterminado
        self.locations_state=[]


        self.tiempo1=time.now()
        #ipcamUrl = 'http://admin:admin@192.168.43.1:8081'
        ipcamUrl = 'http://admin:usher@192.168.43.93:8081'
        ipcam = {}
        ipcamDesc = 'Celular'
        ipcam[ipcamDesc] = urlparse(ipcamUrl)
        print(time.now())
        
        # Prueba la conexión al destino ip
        '''if len(ipcamUrl) > 5:
          err,errMsg = self.urlTest(ipcam[ipcamDesc].hostname,ipcam[ipcamDesc].port)
          if err > 0:
              print(time.now(),"Falló conexión. ",errMsg)
              exit(1)'''
        
        try:
          #self.capture = cv2.VideoCapture(ipcamUrl)
          self.capture = cv2.VideoCapture(0)
          self.capture.set(3,self.CaptureWidth) #1024 640 1280 800 384
          self.capture.set(4,self.CaptureHeight) #600 480 960 600 288
          global x2,y2
          x2=self.CaptureWidth
          y2=self.CaptureHeight
          sys.path.append("..")
        
          # Importación del módulo de detección de objetos.
          from object_detection.utils import label_map_util
          from object_detection.utils import visualization_utils as vis_util
        
          PATH_TO_CKPT = 'modelo_congelado/frozen_inference_graph.pb'
        
          PATH_TO_LABELS = os.path.join('configuracion', 'label_map.pbtxt')
          
          NUM_CLASSES = 90
                  
          self.detection_graph = tf.Graph()
          with self.detection_graph.as_default():
            od_graph_def = tf.GraphDef()
            with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
              serialized_graph = fid.read()
              od_graph_def.ParseFromString(serialized_graph)
              tf.import_graph_def(od_graph_def, name='')
        
        
          label_map = label_map_util.load_labelmap(PATH_TO_LABELS)
          categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)
          self.category_index = label_map_util.create_category_index(categories)
                          
        except IOError as e:
            print(time.now(), "Error abriendo socket: ", ipcamUrl)
        except KeyboardInterrupt as e:
            print(time.now(), "Detenido por teclado.")
        except BaseException as e:
            print(time.now(), "Error desconocido: ", e)
        #    if e.number == -138:
        #        print("Compruebe la conexión con '" + ipcamUrl + "'")
        #    else:
        #        print("Error: " + e.message)
        finally:
            #self.capture.release()
            cv2.destroyAllWindows()
        
        with self.detection_graph.as_default():
            with tf.Session(graph=self.detection_graph) as sess:
              self.sess = tf.Session()
              self.image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')
              # Each box represents a part of the image where a particular object was detected.
              self.detection_boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')
              # Each score represent how level of confidence for each of the objects.
              # Score is shown on the result image, together with the class label.
              self.detection_scores = self.detection_graph.get_tensor_by_name('detection_scores:0')
              self.detection_classes = self.detection_graph.get_tensor_by_name('detection_classes:0')
              self.num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')

              #Creo un timer para:
              # 1) Actualizar la información en pantalla
              # 2) Activar la CNN y obtener datos del analisis
              self.timer = wx.Timer(self)
              self.Bind(wx.EVT_TIMER, self.OnTimer)

              #Inicialmente la CNN está inactiva
              self.analisis=False

              
              self.Bind(wx.EVT_CLOSE, self.onClose)
              self.Bind(wx.EVT_LEFT_UP, self.VentanaClick)

              #Estado del programa
              self.STATE_RUNNING = 1
              self.STATE_CLOSING = 2
              self.state = self.STATE_RUNNING
              
              #Estado del reproductor
              self.STATE_PORTADA = 1
              self.STATE_PELICULA = 2
              self.statePlayer = self.STATE_PORTADA

              #Cantidad de ciclos del timer que la CNN no trabaja
              #Esto es para evitar lag
              self.FREC=20
              self.FRECUENCIA_CNN=0
                
              #Seteo cada cuanto tiempo se activará el timer
              self.fps=40
              self.timer.Start(1000./self.fps)    # timer interval

              self.camara = "Camera"
              cv2.namedWindow(self.camara, cv2.WINDOW_NORMAL)
              cv2.setMouseCallback(self.camara, on_mouse, 0)
              cv2.setWindowProperty(self.camara, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
              sleep(0.1)
              cv2.resizeWindow(self.camara, 320,180)
              cv2.moveWindow(self.camara, 0,0) 
              
              self.appPrincipal = "AppPrincipal"

              #Para traer al frente la toma de la camara
              top_windows = []
              win32gui.EnumWindows(windowEnumerationHandler, top_windows)
              for i in top_windows:
                
                if self.camara in i[1]:
                  self.camaraPID=i[0]
                  win32gui.ShowWindow(i[0],5)
                  win32gui.SetForegroundWindow(i[0])
                  break

              #Para traer al frente la AppPrincipal para capturar eventos
              top_windows = []
              win32gui.EnumWindows(windowEnumerationHandler, top_windows)
              for i in top_windows:
                if self.appPrincipal in i[1]:
                  self.appPrincipalPID=i[0]
                  win32gui.ShowWindow(i[0],5)
                  #win32gui.SetForegroundWindow(i[0])
                  break                   

              rect = win32gui.GetWindowRect(self.camaraPID)
              self.xCamara = rect[0]
              self.yCamara = rect[1]
              self.wCamara = rect[2] - self.xCamara
              self.hCamara = rect[3] - self.yCamara

              self.frequency = 1000  # Set Frequency
              self.duration = 200  # Set Duration To 1000 ms == 1 second

              self.widhtDesktop = GetSystemMetrics(0)
              self.heightDesktop = GetSystemMetrics(1)

              #Oculto la AppPrincipal del escritorio (X,Y,Width,Height)
              sleep(0.1)
              win32gui.ShowWindow(self.appPrincipalPID, win32con.SW_HIDE)
              
              if self.statePlayer == self.STATE_PELICULA:
                #VLC para las peliculas
                self.instance = vlc.Instance()
                self.player = self.instance.media_player_new("Reproductor Peliculas y Portadas")
                self.player.set_fullscreen(True)
                pathVideo = os.path.join(self.PATH_VIDEOS, next(self.listaVideos))
                self.media = self.instance.media_new(pathVideo)
                self.player.set_media(self.media)  
                            
                self.player.play()   
                
                sleep(0.1)
                self.reproductorPID=win32gui.GetForegroundWindow() 
                self.player.pause() 
                self.pause=True
                self.media = self.player.get_media()
              else:
                #VLC para las portadas
                self.instance = vlc.Instance()
                self.player = self.instance.media_player_new()
                self.player.set_fullscreen(True)
                self.media = self.instance.media_new('imagenes/portada.jpg')
                self.player.set_media(self.media)
                
                self.player.play() 
                   
                sleep(0.1)
                self.reproductorPID=win32gui.GetForegroundWindow()
                self.player.pause() 
                self.pause=True
                self.player.set_time(8000)
                self.media = self.player.get_media()

              
              print("Reproductor inicial:",self.reproductorPID)

              
              self.vlcName = "VLC (Direct3D output)"
              self.vlcName2 = "VLC (VLC Video Output)"
              self.reproductorPID=0
              #Obtengo el PID del vlc
              top_windows = []
              win32gui.EnumWindows(windowEnumerationHandler, top_windows)
              for i in top_windows:
                 if self.vlcName in i[1]:
                    self.reproductorPID=i[0]
                    win32gui.ShowWindow(i[0],5)
                    break

              print("Reproductor inicial buscado:",self.reproductorPID)

              #exit(1)
              #win32gui.SetForegroundWindow(self.reproductorPID)


              win32gui.ShowWindow(self.reproductorPID, win32con.SW_MAXIMIZE)  
              #win32gui.ShowWindow(self.portadaPID, win32con.SW_MAXIMIZE)

    def __set_properties(self):
        # begin wxGlade: MyFrame.__set_properties
        self.SetTitle("AppPrincipal")
        self.SetFont(wx.Font(10, wx.FONTFAMILY_DEFAULT, wx.FONTSTYLE_NORMAL, wx.FONTWEIGHT_BOLD, 0, "Arial"))
        self.label_1.SetForegroundColour(wx.Colour(0, 0, 255))
        self.label_1.SetFont(wx.Font(12, wx.FONTFAMILY_SCRIPT, wx.FONTSTYLE_NORMAL, wx.FONTWEIGHT_BOLD, 0, ""))
        self.cantUbicaciones.SetForegroundColour(wx.Colour(0, 0, 255))
        self.cantUbicaciones.SetFont(wx.Font(12, wx.FONTFAMILY_DEFAULT, wx.FONTSTYLE_NORMAL, wx.FONTWEIGHT_BOLD, 0, ""))
        self.label_2.SetForegroundColour(wx.Colour(0, 143, 57))
        self.label_2.SetFont(wx.Font(12, wx.FONTFAMILY_DEFAULT, wx.FONTSTYLE_NORMAL, wx.FONTWEIGHT_BOLD, 0, ""))
        self.cantOcupadas.SetForegroundColour(wx.Colour(0, 143, 57))
        self.cantOcupadas.SetFont(wx.Font(12, wx.FONTFAMILY_DEFAULT, wx.FONTSTYLE_NORMAL, wx.FONTWEIGHT_BOLD, 0, ""))
        self.label_3.SetForegroundColour(wx.Colour(204, 51, 51))
        self.label_3.SetFont(wx.Font(12, wx.FONTFAMILY_DEFAULT, wx.FONTSTYLE_NORMAL, wx.FONTWEIGHT_BOLD, 0, ""))
        self.cantLibres.SetForegroundColour(wx.Colour(203, 50, 53))
        self.cantLibres.SetFont(wx.Font(12, wx.FONTFAMILY_DEFAULT, wx.FONTSTYLE_NORMAL, wx.FONTWEIGHT_BOLD, 0, ""))
        # end wxGlade

    def __do_layout(self):
        # begin wxGlade: MyFrame.__do_layout
        self.sizer_1 = wx.StaticBoxSizer(wx.StaticBox(self, wx.ID_ANY, "DASHBOARD"), wx.VERTICAL)
        self.sizer_3 = wx.StaticBoxSizer(wx.StaticBox(self, wx.ID_ANY, "Mapa de ubicaciones"), wx.VERTICAL)
        grid_sizer_1 = wx.GridBagSizer(0, 0)
        self.sizer_2 = wx.StaticBoxSizer(wx.StaticBox(self, wx.ID_ANY, u"Cámara en vivo"), wx.VERTICAL)
        self.sizer_2.Add((0, 0), 0, 0, 0)
        self.sizer_1.Add(self.sizer_2, 1, wx.EXPAND, 0)
        grid_sizer_1.Add(30, 20, (0, 0), (1, 1), 0, 0)
        grid_sizer_1.Add(self.label_1, (0, 1), (1, 1), 0, 0)
        grid_sizer_1.Add(self.cantUbicaciones, (0, 2), (1, 1), 0, 0)
        grid_sizer_1.Add(30, 20, (0, 3), (1, 1), 0, 0)
        grid_sizer_1.Add(self.label_2, (0, 4), (1, 1), 0, 0)
        grid_sizer_1.Add(self.cantOcupadas, (0, 5), (1, 1), 0, 0)
        grid_sizer_1.Add(30, 20, (0, 6), (1, 1), 0, 0)
        grid_sizer_1.Add(self.label_3, (0, 7), (1, 1), 0, 0)
        grid_sizer_1.Add(self.cantLibres, (0, 8), (1, 1), 0, 0)
        self.sizer_3.Add(grid_sizer_1, 0, wx.TOP, 9)
        self.sizer_3.Add((0, 0), 0, 0, 0)
        self.sizer_1.Add(self.sizer_3, 1, wx.EXPAND, 0)
        self.SetSizer(self.sizer_1)
        self.Layout()
        # end wxGlade

    def OnTimer(self, event):
        
        #ret, self.image_np = self.capture.read()
        ret = self.capture.grab()
        
        if ret == True:
          #print("Captura OK")
          pass
        else:
          print("Falló la captura")
          exit(1)       
        
        global image_np
        ret, image_np = self.capture.retrieve()
        height1, width1, channels = image_np.shape
        #cv2.imshow('object detection', self.image_np)
        global x1,y1,x2,y2
        crop_img = image_np[y1:y2, x1:x2]
        if self.analisis==True:
          if self.FRECUENCIA_CNN==0: 


              #ret, self.image_np = self.capture.retrieve()
              # EXAMPLE GRAY "cv2.COLOR_BGR2GRAY"
              # # EXAMPLE HSV "cv2.COLOR_BGR2HSV"
              # # EXAMPLE RGB ""
                           
              #COLOR = cv2.COLOR_BGR2HSV
              #self.image_np = cv2.cvtColor(self.image_np, COLOR)

              '''COLOR = cv2.COLOR_BGR2GRAY
              self.image_np = cv2.cvtColor(self.image_np, COLOR)
              COLOR = cv2.COLOR_GRAY2BGR
              self.image_np = cv2.cvtColor(self.image_np, COLOR)'''
               
              #cv2.imshow( "Display window",self.image_np); 
              #cv2.waitKey(0);
              #import pdb; pdb.set_trace()
              # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
              image_np_expanded = np.expand_dims(crop_img, axis=0)

              # Actual detection.      
              (self.boxes, self.scores, self.classes, self.num) = self.sess.run([self.detection_boxes, self.detection_scores, self.detection_classes, self.num_detections],feed_dict={self.image_tensor: image_np_expanded})
              
              
              box = np.squeeze(self.boxes)
              #Alto del frame en pixeles
              height = np.size(crop_img, 0)
              #Ancho del frame en pixeles
              width = np.size(crop_img, 1)
              
              ##Comparo cada rectangulo del xml con cada box de la CNN
              ##Si el porcentaje de coincidencia es mayor a PORC_INTERSECCION guardo "[OK] "
              ##Si no, guardo "[ ] "
              self.locations_state=[]
              self.personas=0
              Rectangle = namedtuple('Rectangle', 'xmin ymin xmax ymax')
              PORC_INTERSECCION=0.5

              #Recorro las posiciones del xml
              for j in self.images_location:
                ymin = int(j[1])
                xmin = int(j[0])
                ymax = int(j[3])
                xmax = int(j[2])
                area_xml=(ymax-ymin)*(xmax-xmin)
                rxml = Rectangle(xmin, ymin, xmax, ymax)
                #Para cada posicion recorro las boxes buscando coincidencia
                coincide=False
                self.personasTotales=0

                for index,value in enumerate(self.classes[0]):
                  if self.scores[0,index] > 0.20:
                    if self.category_index.get(value).get('name')=="person":
                      self.personasTotales+=1
                      #print(self.personasTotales)
                      
                      ymin = (int(box[index,0]*height))
                      xmin = (int(box[index,1]*width))
                      ymax = (int(box[index,2]*height))
                      xmax = (int(box[index,3]*width))
                      rbox = Rectangle(xmin, ymin, xmax, ymax)
                      area_interseccion=self.area(rxml, rbox)
                      if(area_interseccion!=None):
                        if area_interseccion>(PORC_INTERSECCION*area_xml):
                          coincide=True     
                     
                if coincide==True:
                  self.locations_state.append("[OK]")
                  self.personas+=1
                else:
                  self.locations_state.append("[ ]")
     
              print ("Se detectaron "+str(self.personas)+" personas\n")
              print (self.locations_state)
              print ("\n")
              

              # Visualization of the results of a detection.
              vis_util.visualize_boxes_and_labels_on_image_array(
              crop_img,
              np.squeeze(self.boxes),
              np.squeeze(self.classes).astype(np.int32),
              np.squeeze(self.scores),
              self.category_index,
              use_normalized_coordinates=True,
              max_boxes_to_draw=100,
              line_thickness=4) 
              
              self.FRECUENCIA_CNN=self.FREC
          else:
              self.FRECUENCIA_CNN-=1
        ###############################################
        if self.analisis==True:
         # Visualization of the results of a detection.
         vis_util.visualize_boxes_and_labels_on_image_array(
         crop_img,
         np.squeeze(self.boxes),
         np.squeeze(self.classes).astype(np.int32),
         np.squeeze(self.scores),
         self.category_index,
         use_normalized_coordinates=True,
         max_boxes_to_draw=100,
         line_thickness=4)
        


        #recuadro de la toma de video
        image_np=cv2.rectangle(image_np,(0,0),(width1,height1),(255, 153, 102),20)
        #self.image_np= cv2.rectangle(self.image_np,(0,0),(width,height),(255,255,255),5)

        #Dibujo area de analisis
        image_np=cv2.rectangle(image_np,pt1=(x1,y1),pt2=(x2,y2),color=(255,0,0),thickness=3)
        
        cv2.imshow(self.camara,image_np)

                      
        #Estado del reproductor
        #self.STATE_PORTADA = 1
        #self.STATE_PELICULA = 2
        #self.statePlayer = self.STATE_PORTADA

        if self.statePlayer == self.STATE_PORTADA:
            #Si termina la portada cargo un nuevo video
            state = self.media.get_state()
            if str(state) == 'State.Ended':
              #Cargo una nueva pelicula

              winsound.Beep(self.frequency, self.duration)

              win32gui.ShowWindow(self.reproductorPID, win32con.SW_MAXIMIZE)
              #win32gui.SetForegroundWindow(self.portadaPID)

              pathVideo = os.path.join(self.PATH_VIDEOS, next(self.listaVideos))
              print("Cargo pelicula:",pathVideo)
              self.media = self.instance.media_new(pathVideo)

              self.player.set_media(self.media)
              
              sleep(0.1)
              #exit(1)
              self.player.play()
              sleep(0.1)
              self.reproductorPID=win32gui.GetForegroundWindow() 
              print("Reproductor al crearlo:",self.reproductorPID)
              self.player.pause() 
              self.pause=True
              self.media = self.player.get_media()


              '''self.reproductorPID=0
              #Obtengo los PID de los vlc
              top_windows = []
              win32gui.EnumWindows(windowEnumerationHandler, top_windows)
              for i in top_windows:
                #print(i)
                if self.vlcName in i[1] or self.vlcName2 in i[1]:
                    self.reproductorPID=i[0]
                    #win32gui.ShowWindow(i[0],5)
                    break

              
              print("Reproductor nuevo buscado:",self.reproductorPID)'''

              sleep(0.01)
              win32gui.ShowWindow(self.reproductorPID, win32con.SW_MAXIMIZE)
              win32gui.SetForegroundWindow(self.reproductorPID)
              

              self.statePlayer = self.STATE_PELICULA
              sleep(0.05)

              self.player.play()
              self.pause=False
              #self.playerplay()
              

        elif self.statePlayer == self.STATE_PELICULA:  
            #Si el video termina cargo nueva portada
            state = self.media.get_state()
            if str(state) == 'State.Ended':
                  
              self.analisis=False
              self.personasTotales=0
              #Cargo una nueva portada
              #win32gui.ShowWindow(self.portadaPID, win32con.SW_HIDE)
              
              #win32gui.ShowWindow(self.appPrincipalPID, win32con.SW_SHOW)
              pathPortada='imagenes/portada.jpg'
              self.media = self.instance.media_new(pathPortada)
            
              print("Cargo portada:",pathPortada)
              self.player.set_media(self.media)
              self.player.play()
              sleep(0.1)
              self.reproductorPID=win32gui.GetForegroundWindow() 
              print("Reproductor al crearlo:",self.reproductorPID)
              self.player.pause() 
              self.pause=True
              self.player.set_time(8000)
              self.media = self.player.get_media()            
              
              #sleep(0.1)
              '''self.reproductor=0
              #Obtengo el PID del vlc
              top_windows = []
              win32gui.EnumWindows(windowEnumerationHandler, top_windows)
              for i in top_windows:
                #print(i)
                if self.vlcName in i[1] or self.vlcName2 in i[1]:
                   self.reproductorPID=i[0]
                   #win32gui.ShowWindow(i[0],5)
                   break

              print("Reproductor nuevo buscado:",self.reproductorPID)'''

              sleep(0.1)
              win32gui.ShowWindow(self.reproductorPID, win32con.SW_MAXIMIZE)
              win32gui.SetForegroundWindow(self.reproductorPID)
              self.statePlayer = self.STATE_PORTADA

        personasAdetectar=1
        if self.forzarPausa==False:
           if self.analisis==True:
               if self.statePlayer == self.STATE_PORTADA and self.personasTotales<personasAdetectar and self.pause==False:
                 self.player.pause()
                 self.pause=True
               else:
                 if self.statePlayer == self.STATE_PORTADA and self.personasTotales==personasAdetectar and self.pause==True:
                   self.player.pause()
                   self.pause=False
      
               if self.statePlayer == self.STATE_PELICULA and self.personasTotales<personasAdetectar and self.pause==False:
                 self.player.pause()
                 self.pause=True
               else:
                 if self.statePlayer == self.STATE_PELICULA and self.personasTotales==personasAdetectar and self.pause==True:
                     self.player.pause()
                     self.pause=False
       
        #Para traer al frente la toma de la camara
        #print("Camara PID:",self.camaraPID)
        win32gui.SetForegroundWindow(self.camaraPID) 

        #Para traer al frente el AppPrincipal
        win32gui.SetForegroundWindow(self.appPrincipalPID)
        #win32gui.ShowWindow(self.appPrincipalPID, win32con.SW_HIDE)
          
        self.timer.Start(1000./self.fps)
        event.Skip()
         

    def configuraciónClick(self, event):  # wxGlade: MyFrame.<event_handler>
        print("Event handler 'configuraciónClick' not implemented!")
        event.Skip()

    def acercaDeClick(self, event):  # wxGlade: MyFrame.<event_handler>
        a=wx.MessageDialog(None,'USHER v1.0 \n Detección de personas con CNN \n\n PROYECTO FINAL 2019 \n Grupo 101','Acerca de',style=wx.OK)
        b=a.ShowModal()
        event.Skip()

    def salirClick(self, event):  # wxGlade: MyFrame.<event_handler>
        self.Close(True)
        event.Skip()

    def cambiarEstadoCNN(self, event):  # wxGlade: MyFrame.<event_handler>
        if self.analisis==True:
              self.analisis=False
        else:
          self.analisis=True
        event.Skip()
        
    def KeyDown(self, event=None):
      keycode = event.GetKeyCode()
      if keycode == wx.WXK_SPACE:
         self.player.pause()
         self.pause=not self.pause
         if self.statePlayer == self.STATE_PELICULA:
           self.forzarPausa=not self.forzarPausa

         
      if keycode == wx.WXK_LEFT:
         self.xCamara=0
         cv2.moveWindow(self.camara, self.xCamara,self.yCamara)
      if keycode == wx.WXK_RIGHT:
         self.xCamara=self.widhtDesktop-self.wCamara
         cv2.moveWindow(self.camara, self.xCamara,self.yCamara)        
      if keycode == wx.WXK_UP:
         self.yCamara= 0
         cv2.moveWindow(self.camara,self.xCamara,self.yCamara)         
      if keycode == wx.WXK_DOWN:
         self.yCamara= self.heightDesktop-self.hCamara
         cv2.moveWindow(self.camara,self.xCamara,self.yCamara)     
      if keycode == wx.WXK_ESCAPE:
         self.Close(True)
      if keycode == wx.WXK_ALT:
         winsound.Beep(self.frequency, self.duration)
         self.is_mute = self.player.audio_get_mute()
         self.player.audio_set_mute(not self.is_mute)
      if keycode == wx.WXK_SHIFT:  
         winsound.Beep(self.frequency, self.duration) 
         self.player.set_time(self.player.get_length())


      if keycode == wx.WXK_CONTROL:
            
         self.analisis=not self.analisis

       

 # end of class MyFrame


    #Al cerrar la ventana paro el timer y elimino el frame
    def onClose(self, event):
        if not self.state == self.STATE_CLOSING:
            self.state = self.STATE_CLOSING
            self.timer.Stop()
            self.Destroy()    

    #Evento que se activa cuando se hace Refresh de algun StaticBitmap(Video o bancas)
    def onPaint(self, event):
       if self.state == self.STATE_RUNNING:
          #Se usa un buffer para evitar parpadeo de la imagen
          #dc = wx.BufferedPaintDC(self.Screen1)
          #dc.DrawBitmap(self.wxbmp, 0, 0)    
          pass
    
    #El fondo no se borra para evitar el parpadeo de la imagen
    def onEraseBackground(self, event):
        return        
        


    #Al hacer click sobre la ventana, cambio el estado de seleccionado False a todas las bancas
    def VentanaClick(self, event): 
        
       #Seteo todas las StaticBitmap des-seleccionadas
       for i in self.screen_list:
         self.dict_bancas[i.getStaticBitmap()].setSeleccionado(False)  

    

    def urlTest(self,host, port):
        
        out = (0,"")
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            s.settimeout(5.6)
        except socket.error as e:
            out = (1, "Error creating socket: %s" % e)
        # Second try-except block -- connect to given host/port
        #else:
           # try:
           #     s.connect((host, port))
           # except socket.gaierror as e:
           #     out = (2, "Address-related error connecting to server: %s" % e)
           # except socket.error as e:
           #     out = (3, "Connection error: %s" % e)
           # finally:
           #     s.close()
        return out

    #A partir de un xml previamente cargado con labelImage, obtengo la posicion de cada ubicacion
    #(correspondiente a cada banca) dentro de la toma de video completa y el nro de banca
    def xml_to_locations(self,path):
        locations_list = []
        for xml_file in glob.glob(path + '/*.xml'):
            tree = ET.parse(xml_file)
            root = tree.getroot()
            for member in root.findall('object'):
                value = (int(member[4][0].text), #xmin
                         int(member[4][1].text), #ymin
                         int(member[4][2].text), #xmax
                         int(member[4][3].text), #ymax
                         int(member[0].text), #nro banca                        
                         )
                locations_list.append(value)
        return locations_list



    
    #Area de interseccion entre 2 rectangulos
    #Para determinar coincidencia entre las posiciones del xml y las boxes de la CNN
    def area(self,a, b):  # returns None if rectangles don't intersect
        dx = min(a.xmax, b.xmax) - max(a.xmin, b.xmin)
        dy = min(a.ymax, b.ymax) - max(a.ymin, b.ymin)
        if (dx>=0) and (dy>=0):
            return dx*dy
            
class MyApp(wx.App):

    def OnInit(self):
        #def __init__(self, *args, **kwds):
        self.frame = MyFrame(None, wx.ID_ANY, "")
        self.SetTopWindow(self.frame)
        #self.frame.Show()
        return True

# end of class MyApp

if __name__ == "__main__":
      
      
    app = MyApp(0)
    app.MainLoop()
    
